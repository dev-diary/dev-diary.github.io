[
  
    {
      "category" : "Jekyll, SSL, Github, Google",
      "title"    : "How to set up custom domain for Github Pages with HTTPS",
      "description": "The purpose of this guide is to add a custom domain pointing to the website o...",
      "content": "The purpose of this guide is to add a custom domain pointing to the website on Github Pages. The domain will use an SSL certificate. Finally, we’ll add the domain to Google. The whole operation takes only a few minutes and can be done in a few steps.Requirements:  Purchased domain (I bought it on porkbun.com. You can buy domain anywhere, for example on Google Domains)  A github pages repository, e.g. https://github.com/username/username.github.ioAdd custom domain to Github Pages settingsGo to your github repository settings page:Add you custom domain name (www.domain) at Settings -&amp;gt; GitHub Pages -&amp;gt; Custom domain:Point your custom domain to your Github Page`s websiteIf you also use Porkbun, you can easily point the domain to your GitHub pages using the guide: Connect domain to Github PagesIf you use Google Domains, select your domain in the Admin panel. Then go to DNS&amp;gt; Custom resource records and add the DNS records:  185.199.111.153  185.199.110.153  185.199.109.153  185.199.108.153  Add the CNAME record: name - www, type - CNAME, answer/value - yoursite.github.ioEnable HTTPS for your GitHub pages websiteGo to your GitHub repository settings. Under Settings &amp;gt; GitHub Pages &amp;gt; Custom domain check the Enforce HTTPS checkbox.After a while (up to several hours) your domain should be available once with an SSL certificate. Go to https://yourdomain and check if you can see your website.NET::ERR_CERT_COMMON_NAME_INVALID errorIf after entering https: //yourdomain you see a browser warning and NET :: ERR_CERT_COMMON_NAME_INVALID error - make sure that you put www.yourdomain under Settings &amp;gt; GitHub Pages &amp;gt; Custom domain.  Adding the www prefix should fix the problem.Verify Domain in Google Search Console via DNSTo add your website to Google search, you must verify your domain on Google Search Console .      Select Domain property type:http://    Copy the TXT record you’ll get:  Log into your domain`s admin panel.  Add a new DNS record and select TXT as a record type.  Fill  fields with the following information: name/host - empty, TTL - 86400 or default, answer/text -  your Google verification text from previous step.  Click Verify.Your domain can not be verified right away in Search Console. If you see a similar view to the picture below - this means that your website has not yet been confirmed.It may take a few minutes (up to 48 hours) to update your DNS. In my case, the domain was verified in 10 minutes. That`s all! There’s no guaranteed time-frame for how long it will take for your website to appear in Google’s search results. It can take anywhere from hours to weeks.Thanks for reading the post. See you later!",
      "url"      : "/blog/How-to-set-up-custom-domain-for-Github-Pages-with-HTTPS/",
      "image"    : "/images/github-custom-domain.jpg",
      "author"   : "Michal Fabjanski"
    }
    ,
  
    {
      "category" : "Jekyll, CircleCI",
      "title"    : "Creating Jekyll Automated Deployment to GitHub Pages with CircleCI",
      "description": "A few days ago I logged in to Google Webmaster Tools to check if my blog is a...",
      "content": "A few days ago I logged in to Google Webmaster Tools to check if my blog is already available on google. I was surprised because the site was blocked. The addresses in sitemap.xml pointed to localhost: 4000/page-address. It’s all because I was building a blog locally and pushing a ready, built version from _sites directory to GitHub repository. I thought I would automate the deployment  process using one of the to Cl/CD - CircleCICircleCICircleCI provides very interesting (and free, which is important for me) service that allows you to utilize continuous integration in your development process.  CircleCI seamlessly integrates with GitHub, GitLab, BitBucket so you can automate your build, test, and deploy pipeline. There are many other Continuous Integration tools available on a market (Travis CI, Go CD, GitLab CI) however, I liked CircleCi the most. I encourage you to read the documentation.Requirements:  Github account  Repository with the Jekyll blog source code  Blog template based on JekyllAutomatically deploying Jekyll blog to GitHub PagesCurrently, I have one public repository to which I push the contents of the locally generated _site folder. I want to prepare:  A private repository with the entire Jekyll template code (I do not want to share my template code on the public repo)  A public repository to which CircleCI pipeline will push the generated _site contentIn my case, these two repositories are in different GitHub accounts. This is because I created a separate account for my blog. However, this does not matter when it comes to building automation.CircleCI ConfigurationFirst, log in to CircleCi  using the Github account. If you have two accounts like me (One for the blog, the second for yourself) - use the second one. This is where we will store the entire Jekyll template code in the private repository.After logging in you should see your repositories. Select the repository where you will store the entire template code.Now we have to define a deployment pipeline. CircleCI configuration is stored in a single YAML file located at .circleci/config.yml in the root of your project’s directory.Config.ymlDetailed instructions on how to create configuration can be found on the https://circleci.com/docs/2.0/writing-yaml/.My configuration is simple and contains only a few steps:defaults: &amp;amp;defaults    working_directory: ~/repo  version: 2  jobs:    build:      &amp;lt;&amp;lt;: *defaults    docker:        - image: circleci/ruby:2.6      environment:      steps:        - checkout        - run:            name: Bundler Install            command: gem install bundler        - run:            name: Rsync Install            command: sudo apt install rsync        - run:            name: Install Dependencies            command: bundle install        - run:            name: Jekyll build            command: bundle exec jekyll build        - deploy:            name: Deploy Blog to GitHub            command: |              if [ $CIRCLE_BRANCH == &#39;master&#39; ]; then                bash .circleci/deploy.sh              fi  workflows:    version: 2    build:      jobs:        - buildI used a CircleCI pre-built docker image that comes with tools that are useful to build Jekyll theme (Ruby and Rails image). In my pipeline, I install the bundler, which is needed to install all of the dependencies specified in the Gemfile file. I build a template just like locally - using bundle exec Jekyll build. You probably wonder why I added the  Rsync Install step.  This is to synchronize the newly generated theme with the currently used. In Linux, you can not move files with overwriting, that’s why I’m using Rsync.Deploy.sh script# Clone Jekyll generated template repository  git clone https://&amp;lt;GitHub Personal access token&amp;gt;@github.com/dev-diary/dev-diary.github.io.git  cd dev-diary.github.io    # Adding only files that have changed to the currently used template rsync -a ../_site/ .    #Setting GIT user  git config --global user.email &quot;michael.fabjanski@gmail.com&quot;  git config --global user.name &quot;Michal&quot;    # Preparation of backup branch name with (Branch from before new change)  BRANCH_NAME=backup-$(date -d &quot;today&quot; +&quot;%Y%m%d%H%M&quot;)  git checkout -b $BRANCH_NAME  git push -q https://7d2c83a2ddc30630bb41d19177775e30c09d29b1@github.com/dev-diary/dev-diary.github.io.git $BRANCH_NAME    #Add new changes to the generated template code and push it  git checkout master  git add .  git commit -m &quot;Builded new version - $(date -d &quot;today&quot; +&quot;%Y%m%d%H%M&quot;)&quot;  git push -q https://&amp;lt;GitHub Personal access token&amp;gt;@github.com/dev-diary/dev-diary.github.io.gitI clone the repository with the generated template. Then I only add new changes (generated by the pipeline in the _site folder). Because I use the second repository for the blog (it is not connected to CircleCi), I had to generate GitHub Personal access token.Before the commit, I create a branch with back up.In the end, I commit the changes and push to the repository with the generated theme.Let’s run our pipelineAfter adding my private repository with the entire template code in CircleCI - the tool automatically triggers builds after each commit.This is the sample build:After each commit to the master in my private repository, after about 30 seconds, a new commit is added to the public blog repository.You must use Bundler 2 or greater with this lockfile errorIf your build was a fail and you saw this message: warn_for_outdated_bundler_version&#39;: You must use Bundler 2 or greater with this lockfile - you have to add gem update --system step before installing bundler (See more on GitHub)Testing in CIIt is good practice to automatically test new functionalities before deployment. You can use HTML Proofer - set of tests to validate HTML. It is required to add a dependency to the Gemfile: gem  &#39;HTML-proofer&#39; and one more step to circle.yml:      - run:            name: Run Tests          command: bundle exec htmlproofer ./_site -check-htmlSummaryIt works! I have a private repository with the code of my template. I am the only one who has access to theme code. After each commit on the master branch - my template is automatically built and pushed to Github pages repository. Within a few seconds after pushing changes, the new version of the blog is available online.",
      "url"      : "/blog/Creating-Jekyll-Automated-Deployment-With-CircleCI/",
      "image"    : "/images/Automated-deployment-With-CircleCI.jpg",
      "author"   : "Michal Fabjanski"
    }
    ,
  
    {
      "category" : "java, oop, interview",
      "title"    : "Object Oriented Design Principles Everythone Should Know",
      "description": "During my study, I have collected quite a large and interesting list of objec...",
      "content": "During my study, I have collected quite a large and interesting list of object-oriented programming  design principles that may be useful to you.  This post is a shortened note. I invite you to explore knowledge reading books such as “Clean Architecture”, Martin Robert C.  Ready? I invite you to read the 10 most important OOP principles.Object-Oriented Design Principles represent a set of rules that are the essence of object-oriented programming and help us/others to prepare well, easy to understand design.SOLIDSolid is a set of five rules which tell us how to arrange our methods and data structures in classes. There are three main goals to understand and use SOLID: ✓ Code and functionality changes are easier ✓ Code is easy to understand ✓ Software structures are the basis of components that can be used in many software systems There are five SOLID principles (each letter - one principle):Single Responsibility PrincipleSingle Responsibility Principle tells us that each software entity (classes, modules, methods) is designed to assume only one responsibility. If a code change is to be made, we should need to make a changes in one class that processes it. The good example is the Employee class from a company application:public class Employee {    private String firstName;    private String lastName;    private BigDecimal salaryInUSD;    private BigDecimal salaryInEuro;    public Double getSalaryInPLN() {        return salaryInUSD * Exchange.getDollarToZlotyRate();    }    public Double getSalaryInEuro() {        return salaryInEuro * Exchange.getDollarToEuroRate();    }Why Employee class have to know something about currency exchange?  By putting these two methods into a single Employee class, the developers have coupled Employee class with class responsible for exchange rates. How to do it to comply with the Single Responsibility Principle? We should remove getSalary.. methods from Employee class and create new class (e.g ExchangeService, SalaryCalculator, SalaryConverter…) which has knowledge of exchange rates. Next, we should provide a salary to ExchangeService class. ExchangeService takes the salary, calculate salary in another currency and return it.Open/closed principleOpen/closed principle tell us that sofware entities should be open for extension, but closed for modification. Developer’s goal is to extend a class/module functionality without modyfying its source code. Let’s imagine creating a Square class. In accordance with the Single Responsibility Principle, you create a Square class and AreaCalculator which contain the method calculateArea().See the following example:public class Rectangle {    private double length;}public class AreaCalculator {        public double calculateArea(Square shape) {        return shape.getLength() * shape.getLength();    }}Unfortunately, after some time we get a new task - we have to add two new figures: a triangle and a trapeze. The only solution is to modify the calculateArea() method:public class AreaCalculator {    public double calculateArea(Square shape) {        if (shape instanceof Square) {            return shape.getLength() * shape.getLength();        } else if (shape instanceof Triangle) {            return (shape.getLength() * shape.getHeight()) / 2;        } else if (shape instanceof Trapeze) {            return (...);        } else {            return new RuntimeException(&quot;Cannot calculate area for provided shape&quot;);        }    }}This code starts to look like Arrow Anti-Pattern How to do it in accordance with O/C principle? You should use Shape interface:public interface Shape {    double getArea();}And implementation:public class Suqare implements Shape {    private double length;    @Override    public double getArea() {        return (length * length);    }}Thanks to it AreaCalculator does not have to know all kinds of shapes. It relying on Shape abstraction:public class AreaCalculator {    public double calculateArea(Square shape) {       return shape.getArea();    }}We’ve just made AreaCalculator closed for modification. If we get the task of creating a new shape - we will not have to modify this class. However, we can extend it.Liskov Substitution PrincipleLiskov Substitution Principle is a rule about the contract of the clasess: if a base class satisfies a contract, then by the LSP derived classes must also satisfy that contract. The main objectives of this principle are: ✓ Classes in the application should be swapped by their subclasses without affecting the correctness of the program, i.e. the inheriting class must be a good equivalent of the base class. ✓A subclass should not do less than the base class. So it should always do more. Good example is the“Square extends Rectangle” class:public class Rectangle {    private int height;    private int width;    public void setHeight(int newHeight) {        this.height = newHeight;    }    public void setWidth(int newWidth) {        this.width = newWidth;    }    public int getWidth() {        return width;    }    public int getHeight() {        return height;    }}Mathematically, a square is a rectangle. Most people would misinterpret “is a” relation and model the relationship between the rectangle and a square with inheritance:public class Square extends Rectangle {    @Override    public void setHeight(int height) {        super.setHeight(height);    }    @Override    public void setWidth(int width) {        super.setWidth(width);    }}As you probably guess, you can not have two different dimensions for a square. It is possible to bypass this by:public class Square extends Rectangle {    @Override    public void setHeight(int height) {        super.setHeight(height);        super.setWidth(height);     }    @Override    public void setWidth(int width) {        super.setWidth(width);         super.setHeight(width);    }}We overrided setHeight and setWidth methods to set both dimensions to the same value.  What do you think of this fix?This design breaks LSP. A client can works with instances of Rectangle, but breaks when instances of Square  are passed to it:double countArea(Rectangle rec) {    rec.setWidth(10);    rec.setHeight(5);//It will be a fail for the square:    assertThat(rec.area() == 50);}How to do it correctly? The most critical aspect to inheritance is that we should model inheritance based on behaviours, not object properties. The easiest way to understand this is by way of example:interface Shape {    public double area();}public class Square implements Shape {    private double size;    public void setSize(double size) {        this.size = size;    }    @Override    public double area() {        return size * size;    }}public class Rectangle implements Shape {    private double height;    private double width;    public void setWidth(double width) {        this.width = width;    }    public void setHeight(double height) {        this.height = height;    }    @Override    public double area() {        return height * width;    }}Now clients of Shape cannot make any behavior changes via setter methods. When clients have to change properties of shapes, they have to do it in concrete classes.Interface Segregation PrincipleThe main assumption of the ISP:  No client should be forced to depend on methods it does not use.in other words:  Many client-specific interfaces are better than one general purpose interface.So interfaces that we create should not contain methods that we do not need. The class that implements the interface can not be forced to implement methods that it does not need, and this is often the case with large interface.Let us understand the interface segregation principle by below example:public interface GenerateTimeSheet{  public void generateExcel();  public void generateCSV();}We have one interface with two methods to generate time sheet report (e.g for Employee). Consider a case client TimeSheet wants to use this interface but want to use only Excel time sheets. The interface forces client to implement an unnecessary method generateCSV();.A better solution would be breaking the GenerateTimeSheet interface into two small ones which contains separate methods.Dependency Inversion PrincipleThe general idea of this principle is as simple: High-level modules, which provide complex logic, should be easily reusable and unaffected by changes in low-level modules.Robert C. Martin’s definition of the Dependency Inversion Principle consists of two goals:  High-level modules should not depend on low-level modules. Both should depend on abstractions.  Abstractions should not depend on details. Details should depend on abstractions.In practice DIP tells that a method requires an interface object instead of specific class. This way we can pass many different versions of our entity into the same method.public class EventService {    private DBRepository repository = new DBRepository();    public void addEvent(Event event) {        repository.saveEvent(event);    }    public void removeEvent(String event) {        repository.deleteEvent(event);    }}EventService class uses concrete DBRepository class which save or delete events from the database. In above example EventService is High-level module.  DBRepository is a low-level module. We have a direct dependence between classes here. In this way, we violate the DIP policy. How to do it correctly? To solve the above problem, we should make the EventService class not dependent on the DBRepository class. In addition, both classes must depend on abstraction. Let’s create an abstraction - Repository interface. It will have methods for writing and reading tasks:  public interface Repository {      void saveEvent(Event Event);      void deleteEvent(Event event); } Let’s change the EventService class to use the Repository interface and thus depend on abstraction: public class EventService {    private Repository repository;    public EventService(Repository repository) {        this.repository = repository;    }    public void addEvent(Event event) {        repository.saveEvent(event);    }    public void removeEvent(String event) {        repository.deleteEvent(event);    }} Now we have to implement our DBRepository class (it will also depend on abstraction):public class DBRepository implements Repository {    @Override    public void saveEvent(Event event) {    }    @Override    public void deleteEvent(Event event) {    }} Relationships have been inverted. Now the “high level module” does not depend on the “low level module”. The lower layer module depends on the abstract interface from the upper layer (Repository interface). Changes in the module at the lower level do not affect the module at a higher level.If, for example, we need to save events in the file instead of in a database it is simple. It is enough to add the appropriate class at a lower level (FileRepository).DRY - Don’t Repeat YourselfWe should write a code that is reusable, not repeat the logic contained in one place in the application. If you are close to the copy/paste code, think about creating an abstraction (loop, common interface, function, class, some design pattern, eg Strategy, etc.) that you will be able to repeatedly use.KISS - Keep it simple, stupid!Simplicity (and avoiding complexity) should be a priority during programming. The code should be easy to read and understand, requiring as little effort as possible.Each method should only solve one small problem, not many use cases. If you have a lot of conditions in the method, break these out into smaller methods.This is not only about the way the code is created and written, but also about the names of our classes, methods, variables and objects. Everything should be written in such a way that the name of the variable, object, method or class tells what its purpose or use is.YAGNI - You Aint’t gona need itThis is a nice principle that says that in our program we should put the most important functionalities that we will need at a given moment. We should not write code that will not be useful at the moment, which will be redundant and which will only grow unnecessarily in our program.ADP - Acyclic dependencies principleThis principle says that there should be no cycles in the dependency structure.An exemplary structure breaking this principle will be when: packet A has a dependency in packet B, which has a relationship in packet C, which in turn has a relationship in packet A:We can prevent this by using the Dependency inversion principle, design patterns (eg Observer) or create a new package and put all the common dependencies there.LoD - Law of DemeterThe Law of Demeter is often described this way:  “Only talk to your immediate friends.”This principle says that a class’s method can only refer to:  methods of the same class  fields (and their methods) of the same class  parameters (and their methods) passed to this method  objects (and their methods) that this method will createAdvantages:  reduction of dependence  the code calling the given method does not have to know the structure of other objects  changes in other objects do not require changing the method",
      "url"      : "/blog/10-Object-oriented-design-principles-everythone-should-know/",
      "image"    : "/images/Object-Oriented-Design-Principles.jpg",
      "author"   : "Michal Fabjanski"
    }
    ,
  
    {
      "category" : "java, non-blocking",
      "title"    : "java.nio - How to build a simple non-blocking server in Java?",
      "description": "Building non-blocking server in JavaSome time ago (after Spring 5 release wit...",
      "content": "Building non-blocking server in JavaSome time ago (after Spring 5 release with WebFlux) I started getting interested in non-blocking http servers (Java reactive frameworks are based on this). That’s why I decided to write a post in which I will show how to create a non-blocking server and a client. We will send messages from the client to the server and display them.Let’s start!What is non-blocking server?In the traditional approach, the server listens in the loop for any traffic on a given port. As soon as a new request appears, it delegates the request to previously created thread pool. This approach has some disadvantages. Firstly, the number of concurrently served clients have to be at most equal to the size of the thread pool. Moreover, if any client has weak internet connection - then the thread assigned to his request wastes most of the time waiting for more bits.In non-blocking approach - one thread can handle multiple queries at a time. How? Thanks to the non-blocking IO implemented in java.nio.package.java.nioJava New IO (nio) was created in JDK 1.4 to allow all  programmers to implement very fast input/output without having to deal with custom native code.It was built based on three main functionalities: buffers, channels and selectors.BuforBufor is a block of memory used to temporarily store data while it is being moved from one place to another.ChannelChannel represents a connection to an objects that are capable of performing I/O operations, such as files and sockets. It uses buffers from which it reads the data to send and writes received information.SelectorSelector is one of Java NIO class. The priciple of selector is very simple. After creation, we have to register in selector all the channels that we want to listen to. As a result of this operation, each channel is assigned with selectionKey. SelectionKey is an object that identyfying channel and contains information about channel’ status (e.g readiness to accept request). Each key holds information about who is making the request and what type of the request is.This is, each instance of Selector can monitor more socket channels and thus more connections. When something happens on the channel, the selector informs the application to process the request.Create NIO ServerLet’s code! We will create our non-blocking server and client. Server will accept connections on port 8089 on localhost. We set it by using ServerSocket’s bind() method. To make the server non-blocking we will set ServerSocketchannel’s configureBlocking() method to false. Take a look at the following implementation:public class NonBlockingServer {    private static Selector selector = null;    public static void main(String[] args) {        try {            selector = Selector.open();//            We have to set connection host, port and non-blocking mode            ServerSocketChannel socket = ServerSocketChannel.open();            ServerSocket serverSocket = socket.socket();            serverSocket.bind(new InetSocketAddress(&quot;localhost&quot;, 8089));            socket.configureBlocking(false);            int ops = socket.validOps();            socket.register(selector, ops, null);            while (true) {                selector.select();                Set&amp;lt;SelectionKey&amp;gt; selectedKeys = selector.selectedKeys();                Iterator&amp;lt;SelectionKey&amp;gt; i = selectedKeys.iterator();                while (i.hasNext()) {                    SelectionKey key = i.next();                    if (key.isAcceptable()) {//                        New client has been accepted                        handleAccept(socket, key);                    } else if (key.isReadable()) {//                        We can run non-blocking operation READ on our client                        handleRead(key);                    }                    i.remove();                }            }        } catch (IOException e) {            e.printStackTrace();        }    }    private static void handleAccept(ServerSocketChannel mySocket,                                     SelectionKey key) throws IOException {        System.out.println(&quot;Connection Accepted...&quot;);        // Accept the connection and set non-blocking mode        SocketChannel client = mySocket.accept();        client.configureBlocking(false);        // Register that client is reading this channel        client.register(selector, SelectionKey.OP_READ);    }    private static void handleRead(SelectionKey key)            throws IOException {        System.out.println(&quot;Reading...&quot;);        // create a ServerSocketChannel to read the request        SocketChannel client = (SocketChannel) key.channel();        // Create buffer to read data        ByteBuffer buffer = ByteBuffer.allocate(1024);        client.read(buffer);//        Parse data from buffer to String        String data = new String(buffer.array()).trim();        if (data.length() &amp;gt; 0) {            System.out.println(&quot;Received message: &quot; + data);            if (data.equalsIgnoreCase(&quot;exit&quot;)) {                client.close();                System.out.println(&quot;Connection closed...&quot;);            }        }    }} You certainly noticed two important methods in the main loop of our server:isAcceptable() - checking if client is requesting a connection and isReadable() - method to read data when client has prepared data. IsReadable()will read data from the channel and put it into buffer. Next, we will send data from buffer onto the screen.Create ClientOur client is simple. We also use SocketChannel to connect to the channel and send messages in the buffer. At the end we close SocketChannel.  public class ServerClient {        public static void main(String[] args) {          try {              String[] messages = {&quot;I like non-blocking servers&quot;, &quot;Hello non-blocking world!&quot;, &quot;One more message..&quot;, &quot;exit&quot;};              System.out.println(&quot;Starting client...&quot;);              SocketChannel client = SocketChannel.open(new InetSocketAddress(&quot;localhost&quot;, 8089));                for (String msg : messages) {                  System.out.println(&quot;Prepared message: &quot; + msg);                  ByteBuffer buffer = ByteBuffer.allocate(1024);                  buffer.put(msg.getBytes());                  buffer.flip();                  int bytesWritten = client.write(buffer);                  System.out.println(String.format(&quot;Sending Message: %s\nbufforBytes: %d&quot;, msg, bytesWritten));              }                client.close();              System.out.println(&quot;Client connection closed&quot;);            } catch (IOException e) {              e.printStackTrace();          }      }  }   Connecting client to our serverWe have a client and a server ready. Let’s run it! I wll start with the server (it must be ready when the client sends a message).  Below you can see the result of client&amp;lt;-&amp;gt;server communication.Client:    Starting client...    Prepared message: I like non-blocking servers    Sending Message: I like non-blocking servers    bufforBytes: 27    Prepared message: Hello non-blocking world!    Sending Message: Hello non-blocking world!    bufforBytes: 25    Prepared message: One more message..    Sending Message: One more message..    bufforBytes: 18    Prepared message: exit    Sending Message: exit    bufforBytes: 4    Client connection closed    Server:    Connection Accepted...    Reading...    Received message: I like non-blocking servers    Reading...    Received message: Hello non-blocking world!    Reading...    Received message: One more message..    Reading...    Received message: exit    Connection closed...     SummaryI hope you liked this post. The server and client code is available on github: REPO URL.See you next time!",
      "url"      : "/blog/java.nio-How-To-Build-a-non-blocking-server-in-java/",
      "image"    : "/images/java_nonblocking_server.jpg",
      "author"   : "Michal Fabjanski"
    }
    ,
  
    {
      "category" : "openhift, kubernetes",
      "title"    : "Remote JMX Connection to Openhift (or Kubernetes) pod",
      "description": "Remote Debugging Applications on Openshift podsIn this post I would like to s...",
      "content": "Remote Debugging Applications on Openshift podsIn this post I would like to share my last challenge at work - remote debugging of an application running on Openhift. This method is also valid for Kubernetes pods.Set up JMXThe first thing you have to do is to enable and configure JMX flags. Start your program with following parameters:-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=3000-Dcom.sun.management.jmxremote.rmi.port=3001-Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=127.0.0.1JMX use RMI for the communication between the JMX client and the remote JVM. That’s why I’ve set two ports. JMX client will connect to hostname - 127.0.0.1:3001. You probably wonder how it can work if there is no RMI server running on localhost. This is because the next step is to set up Openshift/Kubernetes port forwarding.Port forwardingThanks to port forwarding feature you can forward one or more local ports to a pod.  You need to be locally logged on the Openhift. If you do not have it yet - I recommend downloading OpenShift Client Tools (Windows, Linux)Use following command to start the proxy and forward ports to the remote pod:oc login #login to Openshiftoc project #switch to your projectoc port-forward &amp;lt;POD-NAME&amp;gt; 8080 3000 3001Remember to replace  with the name of your pod. After that you shuld see output:oc port-forward my-app-46ztp 8080 3000 3001Forwarding from 127.0.0.1:8080 -&amp;gt; 8080Forwarding from 127.0.0.1:3000 -&amp;gt; 3000Forwarding from 127.0.0.1:3001 -&amp;gt; 3001JVisualVM connectionIf you have started proxy on the machine where you run JVisualVM, you can connect locally to RMI port: visualvm --openjmx localhost:3000",
      "url"      : "/blog/Remote-JMX-Connetion-to-Openhift-Pod/",
      "image"    : "/images/openshift-jmx.jpg",
      "author"   : "Michal Fabjanski"
    }
    
  
]
